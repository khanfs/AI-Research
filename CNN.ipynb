{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQmvWNAi5YOCQMRsUwHRmG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khanfs/AI-Research/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building a CNN to Classify Images from the MNIST Dataset**\n",
        "\n",
        "**Convolutional Neural Networks** for image classification are commonly used for image-related tasks, and they are designed to process data with a grid-like topology, such as images or sound waves.\n",
        "\n",
        "In mathematics, convolution is an operation that combines two functions to produce a third function that describes how one function modifies the other. In the context of neural networks, convolutional layers use a convolution operation to extract features from the input data.\n",
        "\n",
        "Convolutional means that the neural network is using a mathematical operation called convolution to process the input data. This operation involves sliding a small filter (also called a kernel) over the input data and computing a set of features at each location where the filter overlaps with the data. These features are then combined to form a new representation of the input data, which can be further processed by the network.\n",
        "\n",
        "Convolutional layers are particularly well-suited for processing images and other types of spatial data, as they can capture local patterns and structures in the data, regardless of their position or orientation within the image. By stacking multiple convolutional layers on top of each other, a neural network can learn increasingly complex and abstract features, leading to better performance on tasks such as image recognition and object detection."
      ],
      "metadata": {
        "id": "Kzh27hBOVqYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqVbqfFdUjUV",
        "outputId": "323f27c3-444d-4310-9e6e-2f04a4ee410a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.3)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.1.21)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf # Import the TensorFlow library\n",
        "from tensorflow.keras.datasets import mnist # Import the MNIST dataset from the TensorFlow Keras library\n",
        "from tensorflow.keras.models import Sequential # Import the Sequential class, which is a linear stack of neural network layers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D # Import the Dense, Flatten, Conv2D, and MaxPooling2D layers, which are different types of neural network layers that we will use to build our model"
      ],
      "metadata": {
        "id": "7g2szyPcUt9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MNIST Database**: Modified National Institute of Standards and Technology database is a large database of handwritten digits that is commonly used for training various image processing systems. Consists of small, square 28x28 pixel grayscale images of handwritten single digits between 0 and 9: 70,000 image; training set 60,000 images; test set 10,000 images. All images are labeled with the respective digit that they represent."
      ],
      "metadata": {
        "id": "a54IcuINWG8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data() # Load the MNIST dataset and split it into training and testing sets"
      ],
      "metadata": {
        "id": "ulAQWfmgU1Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1. Data Preprocessing**\n",
        "\n",
        "In this code, the input data (images) is being preprocessed by normalizing pixel values to a range between 0 and 1. This is achieved by dividing the pixel values by 255.0, which is the maximum pixel value for grayscale images. Normalizing the pixel values can help the model to converge faster during training and prevent numerical instability.\n",
        "\n",
        "Therefore, x_train and x_test are the training and testing datasets respectively, and dividing them by 255.0 scales all the pixel values in the images between 0 and 1, making them easier for the neural network to process."
      ],
      "metadata": {
        "id": "WzP7zbk-i4hD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "x_train = x_train / 255.0 # Normalize the pixel values in the input images to be between 0 and 1\n",
        "x_test = x_test / 255.0 # Normalize the pixel values in the test images to be between 0 and 1"
      ],
      "metadata": {
        "id": "NBbsOHrdU5vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2. Build the Model**\n",
        "\n",
        "This code defines the architecture of a convolutional neural network (CNN) model using the Keras library:\n",
        "\n",
        "**model = Sequential()**: This creates a new sequential model object, which is a linear stack of layers. It allows us to add layers to the model in a sequential manner.\n",
        "\n",
        "**model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))**: This adds a 2D convolutional layer to the model with 32 filters, each with a 3x3 kernel size. The 'relu' activation function is applied to the output of this layer. The input_shape parameter specifies the shape of the input data, which is a 28x28 grayscale image with one channel.\n",
        "\n",
        "**model.add(MaxPooling2D((2, 2)))**: This adds a max pooling layer to the model with a pool size of 2x2. This layer reduces the spatial dimensions of the output from the previous convolutional layer by taking the maximum value in each 2x2 window.\n",
        "\n",
        "**model.add(Flatten())**: This flattens the output of the previous layer into a 1D array, which can be fed into a fully connected layer.\n",
        "\n",
        "**model.add(Dense(64, activation='relu'))**: This adds a fully connected layer with 64 neurons, each with a 'relu' activation function.\n",
        "\n",
        "**model.add(Dense(10, activation='softmax'))**: This adds the output layer of the model, which has 10 neurons (one for each class in the dataset) and a 'softmax' activation function. The output of this layer represents the probability distribution over the 10 classes.\n",
        "\n",
        "Overall, this code defines a simple CNN architecture with one convolutional layer, one max pooling layer, and two fully connected layers. The output of the model is a probability distribution over the 10 classes in the dataset, and the model is trained to minimize the loss function using the specified optimizer and evaluation metric."
      ],
      "metadata": {
        "id": "X01buXB2h693"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = Sequential() # Create a new sequential model\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) # Add a convolutional layer with 32 filters of size 3x3 and a ReLU activation function to the model, with an input shape of 28x28x1 (since the images are grayscale)\n",
        "model.add(MaxPooling2D((2, 2))) # Add a max pooling layer with a pool size of 2x2 to the model\n",
        "model.add(Flatten()) # Flatten the output of the previous layer into a 1D array\n",
        "model.add(Dense(64, activation='relu')) # Add a fully connected layer with 64 units and a ReLU activation function to the model\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "8VWo6NHYU-vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Compile Model**\n",
        "\n",
        "This line of code in is used to compile a neural network model. It specifies the optimizer, loss function, and evaluation metric that will be used during training.\n",
        "\n",
        "**optimizer='adam'**: This specifies the optimizer that will be used to update the weights of the neural network during training. In this case, the optimizer is 'adam', which is a popular optimization algorithm that is well-suited for deep learning.\n",
        "\n",
        "**loss='sparse_categorical_crossentropy'**: This specifies the loss function that will be used to measure the difference between the predicted output of the model and the true output. In this case, the loss function is 'sparse_categorical_crossentropy', which is commonly used for multiclass classification problems where the target labels are integers.\n",
        "\n",
        "**metrics=['accuracy']**: This specifies the evaluation metric that will be used to measure the performance of the model during training and testing. In this case, the evaluation metric is 'accuracy', which measures the proportion of correct predictions made by the model.\n",
        "\n",
        "Overall, these three settings define how the neural network will be trained and evaluated, and can have a significant impact on the performance of the model."
      ],
      "metadata": {
        "id": "liGUlyi8fXxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jF2nQD-SVDgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4. Train the Model**\n",
        "This is a line of code is used to train a convolutional neural network model. It specifies the training data, number of epochs, and validation data to be used during the training process.\n",
        "\n",
        "**x_train.reshape(-1, 28, 28, 1)**: This specifies the input training data to the model, which is a set of images in this case. The reshape() function is used to convert the input data into a 4-dimensional tensor of shape (batch_size, height, width, channels), where batch_size is the number of training examples, height and width are the dimensions of each image, and channels is the number of color channels (1 for grayscale images, 3 for RGB images).\n",
        "\n",
        "**y_train**: This specifies the target training data, which is a set of labels that correspond to the images in the x_train input data.\n",
        "\n",
        "**epochs=5**: This specifies the number of epochs (iterations over the entire training set) to be used during training. In this case, the model will be trained for 5 epochs.\n",
        "\n",
        "**validation_data=(x_test.reshape(-1, 28, 28, 1), y_test)**: This specifies the validation data to be used during training, which is a set of images and labels that are separate from the training data. The reshape() function is used to convert the validation data into the same 4-dimensional tensor format as the training data. The validation data is used to monitor the performance of the model on data that it has not seen before, and can help to prevent overfitting (when the model memorizes the training data without generalizing well to new data).\n",
        "\n",
        "Overall, this line of code sets up the training process for a convolutional neural network model, and specifies the input and output data to be used during training, the number of epochs to train for, and the validation data to monitor the performance of the model."
      ],
      "metadata": {
        "id": "UP-63nqwgWkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train.reshape(-1, 28, 28, 1), y_train, epochs=5, validation_data=(x_test.reshape(-1, 28, 28, 1), y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5nk46RMVIJt",
        "outputId": "4928146a-c96c-4024-c875-15bac63c6564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 44s 23ms/step - loss: 0.1712 - accuracy: 0.9510 - val_loss: 0.0669 - val_accuracy: 0.9801\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0612 - accuracy: 0.9808 - val_loss: 0.0542 - val_accuracy: 0.9816\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0408 - accuracy: 0.9880 - val_loss: 0.0405 - val_accuracy: 0.9865\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.0482 - val_accuracy: 0.9842\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.0478 - val_accuracy: 0.9843\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f41e75ea520>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5. Evaluate the Model**\n",
        "\n",
        "This line of code is used to evaluate the performance of a trained convolutional neural network model on a test dataset. It computes the model's loss and accuracy on the test dataset and prints the accuracy score.\n",
        "\n",
        "**model.evaluate(x_test.reshape(-1, 28, 28, 1), y_test)**: This evaluates the trained model on the test data, which is a set of images and labels that the model has not seen before. The evaluate() function takes two arguments: the test input data x_test (reshaped to match the format used during training) and the corresponding target labels y_test. It returns two values: the loss (a measure of the difference between the predicted outputs and the true outputs) and the accuracy (the proportion of correct predictions made by the model).\n",
        "\n",
        "**loss, accuracy = model.evaluate(...)**: This line of code assigns the returned values from the evaluate() function to two variables, loss and accuracy, using Python's tuple unpacking syntax. The loss variable stores the loss value computed by the model on the test data, and the accuracy variable stores the accuracy score computed by the model on the test data.\n",
        "\n",
        "**print('Test accuracy:', accuracy)**: This line of code prints the accuracy score of the model on the test data, which is stored in the accuracy variable. The output of this line will be a string that says \"Test accuracy:\" followed by the actual accuracy score.\n",
        "\n",
        "Overall, this code is used to evaluate the performance of a trained convolutional neural network model on a test dataset, and print the accuracy score of the model on the test data."
      ],
      "metadata": {
        "id": "XZJdoFmvhEYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test.reshape(-1, 28, 28, 1), y_test)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRa4jiH4VOfu",
        "outputId": "4955f77d-4c33-4d6c-c354-efa24193fdd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0478 - accuracy: 0.9843\n",
            "Test accuracy: 0.9843000173568726\n"
          ]
        }
      ]
    }
  ]
}